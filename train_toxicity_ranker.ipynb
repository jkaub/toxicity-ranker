{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T14:51:39.888647Z",
     "iopub.status.busy": "2023-08-05T14:51:39.885844Z",
     "iopub.status.idle": "2023-08-05T14:52:04.215481Z",
     "shell.execute_reply": "2023-08-05T14:52:04.214424Z",
     "shell.execute_reply.started": "2023-08-05T14:51:39.888581Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T14:52:04.218200Z",
     "iopub.status.busy": "2023-08-05T14:52:04.217450Z",
     "iopub.status.idle": "2023-08-05T14:52:04.787829Z",
     "shell.execute_reply": "2023-08-05T14:52:04.786760Z",
     "shell.execute_reply.started": "2023-08-05T14:52:04.218161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/validation_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unique messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T14:52:04.790221Z",
     "iopub.status.busy": "2023-08-05T14:52:04.789486Z",
     "iopub.status.idle": "2023-08-05T14:52:06.520752Z",
     "shell.execute_reply": "2023-08-05T14:52:06.519674Z",
     "shell.execute_reply.started": "2023-08-05T14:52:04.790182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in df: 30108\n",
      "Number of unique messages: 14251\n"
     ]
    }
   ],
   "source": [
    "messages = list(set(df.less_toxic.unique()).union(set(df.more_toxic.unique())))\n",
    "print(f\"Number of samples in df: {len(df)}\\nNumber of unique messages: {len(messages)}\")\n",
    "\n",
    "#create an index of messages:\n",
    "index = {messages[i]:i for i in range(len(messages))}\n",
    "\n",
    "#Add a filter column on the dataset based on those index\n",
    "df[\"words_as_index\"] = df.apply(lambda x: [index[x.less_toxic],index[x.more_toxic]],axis=1)\n",
    "\n",
    "#split based on unique messages\n",
    "messages_index = list(range(len(messages)))\n",
    "np.random.shuffle(messages_index)\n",
    "\n",
    "word_train_frac = 0.9 \n",
    "n = len(messages_index)\n",
    "\n",
    "test_words = messages_index[int(n*word_train_frac):]\n",
    "\n",
    "df[\"folds\"] = df[\"words_as_index\"].apply(lambda x: 0 if any([e in test_words for e in x]) else 1)\n",
    "\n",
    "#Split dataset to evaluate the model\n",
    "train_df = df[df.folds == 1]\n",
    "test_messages = messages[int(n*word_train_frac):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tokenizer and model from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T14:52:06.523687Z",
     "iopub.status.busy": "2023-08-05T14:52:06.523236Z",
     "iopub.status.idle": "2023-08-05T14:52:13.711859Z",
     "shell.execute_reply": "2023-08-05T14:52:13.710960Z",
     "shell.execute_reply.started": "2023-08-05T14:52:06.523632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978dd8cf52e94f1a91020479522f2857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6170edcbf1694c33a7042153e3fa1629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d03e17042514c329af84d7d8c9a1213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e18e97ccb714166b54659ccbd668b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549ab1378bdd40c381a96dc5c0462bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "model = AutoModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Custom Pytorch Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T14:52:54.109527Z",
     "iopub.status.busy": "2023-08-05T14:52:54.109140Z",
     "iopub.status.idle": "2023-08-05T14:52:54.119346Z",
     "shell.execute_reply": "2023-08-05T14:52:54.118292Z",
     "shell.execute_reply.started": "2023-08-05T14:52:54.109494Z"
    }
   },
   "outputs": [],
   "source": [
    "last_hidden_layer_size = 768\n",
    "final_node_size = 1\n",
    "\n",
    "class ToxicRankModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model, last_hidden_layer_size):\n",
    "        super(ToxicRankModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.rank_head = nn.Linear(last_hidden_layer_size, 1)\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        output = self.model(input_ids=ids,attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "        output = self.dropout(output[1])\n",
    "        score= self.rank_head(output)\n",
    "        return score\n",
    "    \n",
    "toxicRankModel = ToxicRankModel(model, last_hidden_layer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T14:53:29.414404Z",
     "iopub.status.busy": "2023-08-05T14:53:29.414039Z",
     "iopub.status.idle": "2023-08-05T14:53:29.426024Z",
     "shell.execute_reply": "2023-08-05T14:53:29.424641Z",
     "shell.execute_reply.started": "2023-08-05T14:53:29.414374Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, train_df, tokenizer, max_length):\n",
    "\n",
    "        #token list standard size\n",
    "        self.length = max_length\n",
    "        \n",
    "        #Here the tokenizer will be an instance of the tokenizer\n",
    "        #shown previously\n",
    "        self.tokenizer = tokenizer\n",
    "      \n",
    "        #df is the training df shown in the beginning of the article\n",
    "        self.more_toxic = train_df['more_toxic'].values\n",
    "        self.less_toxic = train_df['less_toxic'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.more_toxic)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # get both messages at index i\n",
    "        message_more_toxic = self.more_toxic[i]\n",
    "        message_less_toxic = self.less_toxic[i]\n",
    "        \n",
    "        #tokenize the messages\n",
    "        dic_more_toxic = self.tokenizer.encode_plus(\n",
    "                                message_more_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.length,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        dic_less_toxic = self.tokenizer.encode_plus(\n",
    "                                message_less_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.length,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        \n",
    "        #extract tokens and masks\n",
    "        tokens_more_toxic = dic_more_toxic['input_ids']\n",
    "        mask_more_toxic = dic_more_toxic['attention_mask']\n",
    "        \n",
    "        tokens_less_toxic = dic_less_toxic['input_ids']\n",
    "        mask_less_toxic = dic_less_toxic['attention_mask']\n",
    "        \n",
    "        #return a dictionnary of tensors\n",
    "        return {\n",
    "            'tokens_more_toxic': torch.tensor(tokens_more_toxic, dtype=torch.long),\n",
    "            'mask_more_toxic': torch.tensor(mask_more_toxic, dtype=torch.long),\n",
    "            'tokens_less_toxic': torch.tensor(tokens_less_toxic, dtype=torch.long),\n",
    "            'mask_less_toxic': torch.tensor(mask_less_toxic, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:00:06.170660Z",
     "iopub.status.busy": "2023-08-05T15:00:06.170262Z",
     "iopub.status.idle": "2023-08-05T15:00:06.177104Z",
     "shell.execute_reply": "2023-08-05T15:00:06.176101Z",
     "shell.execute_reply.started": "2023-08-05T15:00:06.170620Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loader(df, tokenizer, max_length, batch_size):\n",
    "\n",
    "    dataset = CustomDataset(\n",
    "        df, \n",
    "        tokenizer=tokenizer, \n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        drop_last=True)\n",
    "\n",
    "max_length = 128\n",
    "train_loader = get_loader(train_df, tokenizer, max_length, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:00:05.104044Z",
     "iopub.status.busy": "2023-08-05T15:00:05.103681Z",
     "iopub.status.idle": "2023-08-05T15:00:05.112033Z",
     "shell.execute_reply": "2023-08-05T15:00:05.110712Z",
     "shell.execute_reply.started": "2023-08-05T15:00:05.104014Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import MarginRankingLoss\n",
    "\n",
    "#Custom implementation of the MarginRankingLoss with y = 1\n",
    "class CustomMarginRankingLoss(nn.Module):\n",
    "    def __init__(self, margin=0):\n",
    "        super(CustomMarginRankingLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        loss = torch.relu(x2 - x1 + self.margin)\n",
    "        return loss.mean()\n",
    "    \n",
    "def criterion(x1, x2):\n",
    "    return CustomMarginRankingLoss(margin=0.5)(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:00:11.558784Z",
     "iopub.status.busy": "2023-08-05T15:00:11.558407Z",
     "iopub.status.idle": "2023-08-05T15:48:01.901684Z",
     "shell.execute_reply": "2023-08-05T15:48:01.900692Z",
     "shell.execute_reply.started": "2023-08-05T15:00:11.558753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 758/758 [15:54<00:00,  1.26s/it, loss=0.367, accuracy=0.673]\n",
      "Training: 100%|██████████| 758/758 [15:54<00:00,  1.26s/it, loss=0.355, accuracy=0.689]\n",
      "Training: 100%|██████████| 758/758 [15:52<00:00,  1.26s/it, loss=0.333, accuracy=0.715]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device):\n",
    "    #Setup train mode\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\")\n",
    "    \n",
    "    for i, data in progress_bar:\n",
    "        more_toxic_ids = data['tokens_more_toxic'].to(device, dtype = torch.long)\n",
    "        more_toxic_mask = data['mask_more_toxic'].to(device, dtype = torch.long)\n",
    "        less_toxic_ids = data['tokens_less_toxic'].to(device, dtype = torch.long)\n",
    "        less_toxic_mask = data['mask_less_toxic'].to(device, dtype = torch.long)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        #Forward pass both inputs in the model\n",
    "        x1 = model(more_toxic_ids, more_toxic_mask)\n",
    "        x2 = model(less_toxic_ids, less_toxic_mask)\n",
    "        \n",
    "        #Compute margin ranking loss\n",
    "        loss = criterion(x1, x2)\n",
    "        accuracy_measure = (x1 > x2).float().mean().item()\n",
    "        \n",
    "        #apply backpropagation, increment optimizer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #Update cumulative loss for monitoring\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        running_accuracy += (accuracy_measure * batch_size)\n",
    "        epoch_accuracy = running_accuracy / dataset_size\n",
    "\n",
    "        progress_bar.set_postfix({'loss': epoch_loss, 'accuracy': epoch_accuracy}, refresh=True)        \n",
    "        \n",
    "    #Garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "#Get to work of GPU if available else CPU\n",
    "optimizer_lr = 1e-4\n",
    "optimizer_weight_decay = 1e-6\n",
    "scheduler_T_max = 500\n",
    "scheduler_eta_min = 1e-6\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = AdamW(toxicRankModel.parameters(), lr=optimizer_lr, weight_decay=optimizer_weight_decay)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=scheduler_T_max, eta_min=scheduler_eta_min)\n",
    "\n",
    "for i in range(3):\n",
    "    train_one_epoch(toxicRankModel, optimizer, scheduler, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T15:48:13.221429Z",
     "iopub.status.busy": "2023-08-05T15:48:13.221064Z",
     "iopub.status.idle": "2023-08-05T15:48:13.230313Z",
     "shell.execute_reply": "2023-08-05T15:48:13.229271Z",
     "shell.execute_reply.started": "2023-08-05T15:48:13.221398Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomInferenceDataset(Dataset):\n",
    "    def __init__(self, messages, tokenizer, max_length):\n",
    "\n",
    "        #token list standard size\n",
    "        self.length = max_length\n",
    "        \n",
    "        #Here the tokenizer will be an instance of the tokenizer\n",
    "        #shown previously\n",
    "        self.tokenizer = tokenizer\n",
    "      \n",
    "        #df is the training df shown in the beginning of the article\n",
    "        self.messages = messages\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.messages)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # get both messages at index i\n",
    "        message = self.messages[i]\n",
    "\n",
    "        #tokenize the messages\n",
    "        dic_messages = self.tokenizer.encode_plus(\n",
    "                                message,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.length,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "\n",
    "        #extract tokens and masks\n",
    "        tokens_message = dic_messages['input_ids']\n",
    "        mask_message = dic_messages['attention_mask']\n",
    "        \n",
    "        #return a dictionnary of tensors\n",
    "        return {\n",
    "            'tokens_message': torch.tensor(tokens_message, dtype=torch.long),\n",
    "            'mask_message': torch.tensor(mask_message, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T17:06:48.945380Z",
     "iopub.status.busy": "2023-08-05T17:06:48.944986Z",
     "iopub.status.idle": "2023-08-05T17:06:48.999714Z",
     "shell.execute_reply": "2023-08-05T17:06:48.998391Z",
     "shell.execute_reply.started": "2023-08-05T17:06:48.945348Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loader_inference(messages, tokenizer, max_length, batch_size):\n",
    "\n",
    "    dataset = CustomInferenceDataset(\n",
    "        messages, \n",
    "        tokenizer=tokenizer, \n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        drop_last=False)\n",
    "\n",
    "test_messages = pd.read_csv('data/comments_to_score.csv').text.values\n",
    "max_length = 128\n",
    "test_loader = get_loader_inference(test_messages, tokenizer, max_length, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T17:06:49.639028Z",
     "iopub.status.busy": "2023-08-05T17:06:49.638597Z",
     "iopub.status.idle": "2023-08-05T17:06:49.647246Z",
     "shell.execute_reply": "2023-08-05T17:06:49.646049Z",
     "shell.execute_reply.started": "2023-08-05T17:06:49.638994Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_scores(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)\n",
    "    ranks = []  # List to store the rank scores\n",
    "    \n",
    "    progress_bar = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Scoring\")\n",
    "    \n",
    "\n",
    "    for i, data in progress_bar:\n",
    "        tokens_message = data['tokens_message'].to(device, dtype=torch.long)\n",
    "        mask_message = data['mask_message'].to(device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass to get the rank scores\n",
    "        rank = model(tokens_message, mask_message)\n",
    "        # Convert tensor to NumPy and add to the list\n",
    "        ranks+=list(rank.cpu().numpy().flatten())\n",
    "    \n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T17:34:41.955716Z",
     "iopub.status.busy": "2023-08-05T17:34:41.955317Z",
     "iopub.status.idle": "2023-08-05T17:35:34.437532Z",
     "shell.execute_reply": "2023-08-05T17:35:34.436509Z",
     "shell.execute_reply.started": "2023-08-05T17:34:41.955685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 118/118 [00:52<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity score:1.186\n",
      " F*** YOU WIKIPEIA YOU CANT STOP US!!!!!!!!!!!!!!!!\n",
      "F***\n",
      "F***...\n",
      "\n",
      "\n",
      "toxicity score:1.184\n",
      " F*** YOU U USELESS BOT F*** YOU U USELESS BOT F*** YOU U USE...\n",
      "\n",
      "\n",
      "toxicity score:1.183\n",
      " U S***!!!!\n",
      "U S***!!!!'U S***!!!!U S***!!!!'U S***!!!!\n",
      "U S***...\n",
      "\n",
      "\n",
      "toxicity score:1.182\n",
      " YOU ARE A MOTHJER F***ER C*********! YOU ARE A MOTHJER F***E...\n",
      "\n",
      "\n",
      "toxicity score:1.182\n",
      " LEAVE 4 A F**** SNAK AND I RETRN WITH A F**** BLCK YOU ARE A...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = get_scores(toxicRankModel, test_loader, device)\n",
    "mapped_score = pd.Series({mess:score for mess,score in zip(test_messages, scores)}).reset_index().sort_values(0, ascending= False).rename(columns = {\"index\":\"text\",0:\"score\"})\n",
    "mapped_score[\"text\"] = mapped_score[\"text\"].apply(lambda x:x.replace(\"FUCK\",\"F***\").replace(\"COCKSUCKER\",\"C*********\").replace(\"SUCK\",\"S***\").replace(\"FUKIN\",\"F****\"))\n",
    "texts = mapped_score.drop([4757,4758]).head(5)\n",
    "for idx, message in texts.iterrows():\n",
    "    print(f\"toxicity score:{np.round(message.score,3)}\\n\", message.text[:60]+'...\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
